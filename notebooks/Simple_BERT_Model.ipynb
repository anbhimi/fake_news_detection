{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mdeeplearn.soic.iupui.edu\u001b[m  Mon Jul 13 18:06:41 2020\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce GTX 1080   \u001b[m |\u001b[31m 30'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    2\u001b[m / \u001b[33m 8119\u001b[m MB |\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce GTX 1080   \u001b[m |\u001b[31m 30'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    2\u001b[m / \u001b[33m 8119\u001b[m MB |\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[1m\u001b[31m 54'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 4992\u001b[m / \u001b[33m11019\u001b[m MB | \u001b[1m\u001b[30manbhimi\u001b[m(\u001b[33m4989M\u001b[m)\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 27'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    3\u001b[m / \u001b[33m11019\u001b[m MB |\r\n",
      "\u001b[36m[4]\u001b[m \u001b[34mGeForce GTX 1080   \u001b[m |\u001b[31m 28'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    2\u001b[m / \u001b[33m 8119\u001b[m MB |\r\n",
      "\u001b[36m[5]\u001b[m \u001b[34mGeForce GTX 1080   \u001b[m |\u001b[31m 28'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    2\u001b[m / \u001b[33m 8119\u001b[m MB |\r\n",
      "\u001b[36m[6]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 30'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    3\u001b[m / \u001b[33m11019\u001b[m MB |\r\n",
      "\u001b[36m[7]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 29'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    3\u001b[m / \u001b[33m11019\u001b[m MB |\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "# Create and configure logging module\n",
    "log_format = '%(levelname)s %(asctime)s - %(message)s'\n",
    "logging.basicConfig(filename = '../logs/simple_bert_model.logs', \n",
    "                   level = logging.INFO,\n",
    "                   format = log_format,\n",
    "                   filemode = 'w')\n",
    "logger = logging.getLogger()\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 231 ms\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 830 ms\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from random import randrange\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from argparse import ArgumentParser\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce RTX 2080 Ti\n",
      "time: 165 ms\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 391 ms\n"
     ]
    }
   ],
   "source": [
    "## Arguments\n",
    "\n",
    "args = {\n",
    "    'num_labels' : 2\n",
    "    'const' : 1*768\n",
    "    'batch_size' : 16\n",
    "    'epochs' : 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 404 ms\n"
     ]
    }
   ],
   "source": [
    "train_path = '../data/raw/liar_dataset/train.tsv'\n",
    "test_path = '../data/raw/liar_dataset/test.tsv'\n",
    "val_path = '../data/raw/liar_dataset/valid.tsv'\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(train_path, sep=\"\\t\", header=None)\n",
    "test_df = pd.read_csv(test_path, sep=\"\\t\", header=None)\n",
    "val_df = pd.read_csv(val_path, sep=\"\\t\", header=None)\n",
    "\n",
    "# Fill nan (empty boxes) with 0\n",
    "train_df = train_df.fillna(0)\n",
    "test_df = test_df.fillna(0)\n",
    "val_df = val_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10240/10240 [00:00<00:00, 402829.42it/s]\n",
      "100%|██████████| 1267/1267 [00:00<00:00, 321662.32it/s]\n",
      "100%|██████████| 1284/1284 [00:00<00:00, 320316.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 125 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, trange\n",
    "tqdm.pandas()\n",
    "train_df[14] = train_df[1].progress_apply(lambda x: 1 if (x == 'true' or x == 'mostly-true') else 0)\n",
    "test_df[14] = test_df[1].progress_apply(lambda x: 1 if (x == 'true' or x == 'mostly-true') else 0)\n",
    "val_df[14] = val_df[1].progress_apply(lambda x: 1 if (x == 'true' or x == 'mostly-true') else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 207 ms\n"
     ]
    }
   ],
   "source": [
    "true_train_df = train_df[train_df[14] == 1]\n",
    "false_train_df = train_df[train_df[14] == 0]\n",
    "\n",
    "true_test_df = test_df[test_df[14] == 1]\n",
    "false_test_df = test_df[test_df[14] == 0]\n",
    "\n",
    "true_val_df = val_df[val_df[14] == 1]\n",
    "false_val_df = val_df[val_df[14] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 234 ms\n"
     ]
    }
   ],
   "source": [
    "train_data = train_df\n",
    "test_data = test_df\n",
    "val_data = val_df\n",
    "\n",
    "train_data.fillna(value = 0, inplace = True)\n",
    "test_data.fillna(value = 0, inplace = True)\n",
    "val_data.fillna(value = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 176 ms\n"
     ]
    }
   ],
   "source": [
    "train = train_data.values\n",
    "test = test_data.values\n",
    "val = val_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0            1                                                  2   \\\n",
       "0   2635.json        false  Says the Annies List political group supports ...   \n",
       "1  10540.json    half-true  When did the decline of coal start? It started...   \n",
       "2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "\n",
       "                                   3               4                     5   \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "2                      foreign-policy    barack-obama             President   \n",
       "\n",
       "         6           7     8     9      10     11   12               13  14  \n",
       "0     Texas  republican   0.0   1.0    0.0    0.0  0.0         a mailer   0  \n",
       "1  Virginia    democrat   0.0   0.0    1.0    1.0  0.0  a floor speech.   0  \n",
       "2  Illinois    democrat  70.0  71.0  160.0  163.0  9.0           Denver   1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 267 ms\n"
     ]
    }
   ],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.02 s\n"
     ]
    }
   ],
   "source": [
    "labels =        {'train':[train[i][1] for i in range(len(train))], 'test':[test[i][1] for i in range(len(test))], 'val':[val[i][1] for i in range(len(val))]}\n",
    "statements =    {'train':[train[i][2] for i in range(len(train))], 'test':[test[i][2] for i in range(len(test))], 'val':[val[i][2] for i in range(len(val))]}\n",
    "subjects =      {'train':[train[i][3] for i in range(len(train))], 'test':[test[i][3] for i in range(len(test))], 'val':[val[i][3] for i in range(len(val))]}\n",
    "speakers =      {'train':[train[i][4] for i in range(len(train))], 'test':[test[i][4] for i in range(len(test))], 'val':[val[i][4] for i in range(len(val))]}\n",
    "jobs =          {'train':[train[i][5] for i in range(len(train))], 'test':[test[i][5] for i in range(len(test))], 'val':[val[i][5] for i in range(len(val))]}\n",
    "states =        {'train':[train[i][6] for i in range(len(train))], 'test':[test[i][6] for i in range(len(test))], 'val':[val[i][6] for i in range(len(val))]}\n",
    "affiliations =  {'train':[train[i][7] for i in range(len(train))], 'test':[test[i][7] for i in range(len(test))], 'val':[val[i][7] for i in range(len(val))]}\n",
    "credits =       {'train':[train[i][8:13] for i in range(len(train))], 'test':[test[i][8:13] for i in range(len(test))], 'val':[val[i][8:13] for i in range(len(val))]}\n",
    "contexts =      {'train':[train[i][13] for i in range(len(train))], 'test':[test[i][13] for i in range(len(test))], 'val':[val[i][13] for i in range(len(val))]}\n",
    "\n",
    "if num_labels == 6:\n",
    "\n",
    "    def to_onehot(a):\n",
    "        a_cat = [0]*len(a)\n",
    "        for i in range(len(a)):\n",
    "            if a[i]=='true':\n",
    "                a_cat[i] = [1,0,0,0,0,0]\n",
    "            elif a[i]=='mostly-true':\n",
    "                a_cat[i] = [0,1,0,0,0,0]\n",
    "            elif a[i]=='half-true':\n",
    "                a_cat[i] = [0,0,1,0,0,0]\n",
    "            elif a[i]=='barely-true':\n",
    "                a_cat[i] = [0,0,0,1,0,0]\n",
    "            elif a[i]=='false':\n",
    "                a_cat[i] = [0,0,0,0,1,0]\n",
    "            elif a[i]=='pants-fire':\n",
    "                a_cat[i] = [0,0,0,0,0,1]\n",
    "            else:\n",
    "                print('Incorrect label')\n",
    "        return a_cat\n",
    "\n",
    "elif num_labels == 2:\n",
    "\n",
    "    def to_onehot(a):\n",
    "        a_cat = [0]*len(a)\n",
    "        for i in range(len(a)):\n",
    "            if a[i]=='true':\n",
    "                a_cat[i] = [1,0]\n",
    "            elif a[i]=='mostly-true':\n",
    "                a_cat[i] = [1,0]\n",
    "            elif a[i]=='half-true':\n",
    "                a_cat[i] = [0,1]\n",
    "            elif a[i]=='barely-true':\n",
    "                a_cat[i] = [0,1]\n",
    "            elif a[i]=='false':\n",
    "                a_cat[i] = [0,1]\n",
    "            elif a[i]=='pants-fire':\n",
    "                a_cat[i] = [0,1]\n",
    "            else:\n",
    "                print('Incorrect label')\n",
    "        return a_cat\n",
    "\n",
    "else:\n",
    "\n",
    "    print('Invalid number of labels. The number of labels should be either 2 or 6')\n",
    "\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "labels_onehot = {'train':to_onehot(labels['train']), 'test':to_onehot(labels['test']), 'val':to_onehot(labels['val'])}\n",
    "\n",
    "# Credit score calculation\n",
    "credit_score = {'train':[0]*len(train), 'val':[0]*len(val), 'test':[0]*len(test)}\n",
    "for i in range(len(train)):\n",
    "    credit = credits['train'][i]\n",
    "    if sum(credit) == 0:\n",
    "        score = 0.5\n",
    "    else:\n",
    "        score = (credit[3]*0.2 + credit[2]*0.5 + credit[0]*0.75 + credit[1]*0.9 + credit[4]*1)/(sum(credit))\n",
    "    credit_score['train'][i] = [score for i in range(args['const'])]\n",
    "\n",
    "for i in range(len(val)):\n",
    "    credit = credits['val'][i]\n",
    "    if sum(credit) == 0:\n",
    "        score = 0.5\n",
    "    else:\n",
    "        score = (credit[3]*0.2 + credit[2]*0.5 + credit[0]*0.75 + credit[1]*0.9 + credit[4]*1)/(sum(credit))\n",
    "    credit_score['val'][i] = [score for i in range(args['const'])]\n",
    "\n",
    "for i in range(len(test)):\n",
    "    credit = credits['test'][i]\n",
    "    if sum(credit) == 0:\n",
    "        score = 0.5\n",
    "    else:\n",
    "        score = (credit[3]*0.2 + credit[2]*0.5 + credit[0]*0.75 + credit[1]*0.9 + credit[4]*1)/(sum(credit))\n",
    "    credit_score['test'][i] = [score for i in range(args['const'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "class BertLayerNorm(nn.Module):\n",
    "        def __init__(self, hidden_size, eps=1e-12):\n",
    "            \"\"\"\n",
    "            Construct a layernorm module in the TF style (epsilon inside the square root).\n",
    "            \"\"\"\n",
    "            super(BertLayerNorm, self).__init__()\n",
    "            self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "            self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
    "            self.variance_epsilo_n = eps\n",
    "\n",
    "        def forward(self, x):\n",
    "            u = x.mean(-1, keepdim=True)\n",
    "            s = (x - u).pow(2).mean(-1, keepdim=True)\n",
    "            x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
    "            return self.weight * x + self.bias\n",
    "\n",
    "\n",
    "class BertForSequenceClassification(nn.Module):\n",
    "    def __init__(self, num_labels=args['num_labels']): # Change number of labels here.\n",
    "        super(BertForSequenceClassification, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size*1, num_labels)\n",
    "        nn.init.xavier_normal_(self.classifier.weight)\n",
    "\n",
    "    def forward_once(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        return pooled_output\n",
    "\n",
    "    def forward(self, input_ids1):\n",
    "        \n",
    "        input_ids1 = input_ids1.to(torch.device('cuda'))\n",
    "        # forward pass of input 1\n",
    "        output1 = self.forward_once(input_ids1, token_type_ids=None, attention_mask=None, labels=None)\n",
    "\n",
    "        #out = self.fc1(out)\n",
    "        logits = self.classifier(output1)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def freeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "from pytorch_pretrained_bert import BertConfig\n",
    "\n",
    "config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
    "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=args['const'])\n",
    "\n",
    "\n",
    "model = BertForSequenceClassification(num_labels)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mdeeplearn.soic.iupui.edu\u001b[m  Mon Jul 13 18:07:04 2020\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce GTX 1080   \u001b[m |\u001b[31m 30'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    2\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce GTX 1080   \u001b[m |\u001b[31m 30'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    2\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[2]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 49'C\u001b[m, \u001b[32m  2 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 6399\u001b[m / \u001b[33m11019\u001b[m MB | \u001b[1m\u001b[30manbhimi\u001b[m(\u001b[33m4989M\u001b[m) \u001b[1m\u001b[30manbhimi\u001b[m(\u001b[33m1407M\u001b[m)\n",
      "\u001b[36m[3]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 27'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    3\u001b[m / \u001b[33m11019\u001b[m MB |\n",
      "\u001b[36m[4]\u001b[m \u001b[34mGeForce GTX 1080   \u001b[m |\u001b[31m 28'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    2\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[5]\u001b[m \u001b[34mGeForce GTX 1080   \u001b[m |\u001b[31m 28'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    2\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[6]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 31'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    3\u001b[m / \u001b[33m11019\u001b[m MB |\n",
      "\u001b[36m[7]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 29'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    3\u001b[m / \u001b[33m11019\u001b[m MB |\n",
      "time: 492 ms\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.33 s\n"
     ]
    }
   ],
   "source": [
    "# Loading the statements\n",
    "X_train = statements['train']\n",
    "y_train = labels_onehot['train']\n",
    "\n",
    "X_val = statements['val']\n",
    "y_val = labels_onehot['val']\n",
    "\n",
    "X_train = X_train + X_val\n",
    "y_train = y_train + y_val\n",
    "\n",
    "X_test = statements['test']\n",
    "y_test = labels_onehot['test']\n",
    "\n",
    "max_seq_length_stat = 64\n",
    "\n",
    "class text_dataset(Dataset):\n",
    "    def __init__(self,x_y_list, transform=None):\n",
    "\n",
    "        self.x_y_list = x_y_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "\n",
    "        # Tokenize statements\n",
    "        tokenized_review = tokenizer.tokenize(self.x_y_list[0][index])\n",
    "\n",
    "        if len(tokenized_review) > max_seq_length_stat:\n",
    "            tokenized_review = tokenized_review[:max_seq_length_stat]\n",
    "\n",
    "        ids_review  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
    "\n",
    "        padding = [0] * (max_seq_length_stat - len(ids_review))\n",
    "\n",
    "        ids_review += padding\n",
    "\n",
    "        assert len(ids_review) == max_seq_length_stat\n",
    "        \n",
    "        fakeness = self.x_y_list[1][index] # color\n",
    "        list_of_labels = [torch.from_numpy(np.array(fakeness))]\n",
    "        \n",
    "        #print(ids_review)\n",
    "        ids_review = torch.tensor(ids_review)\n",
    "        return [ids_review], list_of_labels[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_y_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 303 ms\n"
     ]
    }
   ],
   "source": [
    "# Train Statements and Justifications\n",
    "train_lists = [X_train, y_train]\n",
    "\n",
    "# Test Statements and Justifications\n",
    "test_lists = [X_test, y_test]\n",
    "\n",
    "# Preparing the data (Tokenize)\n",
    "training_dataset = text_dataset(x_y_list = train_lists)\n",
    "test_dataset = text_dataset(x_y_list = test_lists)\n",
    "\n",
    "# Prepare the training dictionaries\n",
    "dataloaders_dict = {'train': torch.utils.data.DataLoader(training_dataset, batch_size=args['batch_size'], shuffle=True, num_workers=0),\n",
    "                   'val':torch.utils.data.DataLoader(test_dataset, batch_size=args['batch_size'], shuffle=False, num_workers=0)\n",
    "                   }\n",
    "dataset_sizes = {'train':len(train_lists[0]),\n",
    "                'val':len(test_lists[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anbhimi/.local/lib/python3.5/site-packages/torch/optim/lr_scheduler.py:82: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train total loss: 0.6436 \n",
      "train fakeness_acc: 0.6460\n",
      "val total loss: 0.6209 \n",
      "val fakeness_acc: 0.6456\n",
      "Saving with accuracy of 0.6456195737963694 improved over previous 0\n",
      "Time taken for epoch1 is 1.7621575156847635 minutes\n",
      "\n",
      "Epoch 2/5\n",
      "----------\n",
      "train total loss: 0.6181 \n",
      "train fakeness_acc: 0.6677\n",
      "val total loss: 0.6178 \n",
      "val fakeness_acc: 0.6669\n",
      "Saving with accuracy of 0.6669297553275454 improved over previous 0.6456195737963694\n",
      "Time taken for epoch2 is 1.7000805179278056 minutes\n",
      "\n",
      "Epoch 3/5\n",
      "----------\n",
      "train total loss: 0.6106 \n",
      "train fakeness_acc: 0.6778\n",
      "val total loss: 0.6168 \n",
      "val fakeness_acc: 0.6693\n",
      "Saving with accuracy of 0.6692975532754538 improved over previous 0.6669297553275454\n",
      "Time taken for epoch3 is 1.7011373480161032 minutes\n",
      "\n",
      "Epoch 4/5\n",
      "----------\n",
      "train total loss: 0.6066 \n",
      "train fakeness_acc: 0.6827\n",
      "val total loss: 0.6173 \n",
      "val fakeness_acc: 0.6669\n",
      "Time taken for epoch4 is 1.5947534243265789 minutes\n",
      "\n",
      "Epoch 5/5\n",
      "----------\n",
      "train total loss: 0.6056 \n",
      "train fakeness_acc: 0.6854\n",
      "val total loss: 0.6183 \n",
      "val fakeness_acc: 0.6661\n",
      "Time taken for epoch5 is 1.6034053166707356 minutes\n",
      "\n",
      "Training complete in 8m 22s\n",
      "Best val Acc: 0.669298\n",
      "time: 8min 22s\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)\n",
    "\n",
    "logger.info('Training begins')\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "outputs_list = []\n",
    "fakeness_list = []\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=4):\n",
    "    since = time.time()\n",
    "    print('starting')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 100\n",
    "    best_acc = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        logger.info('Training the epoch : {}'.format(epoch+1))\n",
    "        logger.debug('Training stopped at epoch : {}'.format(epoch))\n",
    "        epoch_start = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            fakeness_corrects = 0\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for inputs, fakeness in dataloaders_dict[phase]:\n",
    "                \n",
    "                inputs1 = inputs[0] # News statement input\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    #print(inputs)\n",
    "                    outputs = model(inputs1)\n",
    "\n",
    "                    outputs = F.softmax(outputs,dim=1)\n",
    "                    outputs_list.append(outputs)\n",
    "                    \n",
    "                    fakeness = fakeness.to(torch.device('cuda'))\n",
    "                    fakeness_list.append(fakeness)\n",
    "                    loss = criterion(outputs, torch.max(fakeness.float(), 1)[1])\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs1.size(0)\n",
    "\n",
    "                fakeness_corrects += torch.sum(torch.max(outputs, 1)[1] == torch.max(fakeness, 1)[1])\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "\n",
    "            fakeness_acc = fakeness_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} total loss: {:.4f} '.format(phase,epoch_loss ))\n",
    "            print('{} fakeness_acc: {:.4f}'.format(\n",
    "                phase, fakeness_acc))\n",
    "\n",
    "            # Saving training acc and loss for each epoch\n",
    "            fakeness_acc1 = fakeness_acc.data\n",
    "            fakeness_acc1 = fakeness_acc1.cpu()\n",
    "            fakeness_acc1 = fakeness_acc1.numpy()\n",
    "            train_acc.append(fakeness_acc1)\n",
    "            train_loss.append(epoch_loss)\n",
    "\n",
    "            if phase == 'val' and fakeness_acc > best_acc:\n",
    "                print('Saving with accuracy of {}'.format(fakeness_acc),\n",
    "                      'improved over previous {}'.format(best_acc))\n",
    "                best_acc = fakeness_acc\n",
    "\n",
    "                # Saving val acc and loss for each epoch\n",
    "                fakeness_acc1 = fakeness_acc.data\n",
    "                fakeness_acc1 = fakeness_acc1.cpu()\n",
    "                fakeness_acc1 = fakeness_acc1.numpy()\n",
    "                val_acc.append(fakeness_acc1)\n",
    "                val_loss.append(epoch_loss)\n",
    "\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model.state_dict(), 'bert_model_test_noFC1_triBERT_binary_focalloss.pth')\n",
    "\n",
    "        print('Time taken for epoch'+ str(epoch+1)+ ' is ' + str((time.time() - epoch_start)/60) + ' minutes')\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(float(best_acc)))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, train_acc, val_acc, train_loss, val_loss\n",
    "\n",
    "lrlast = .0001\n",
    "lrmain = .00001\n",
    "optim1 = optim.Adam(\n",
    "    [\n",
    "        {\"params\":model.bert.parameters(),\"lr\": lrmain},\n",
    "        {\"params\":model.classifier.parameters(), \"lr\": lrlast},\n",
    "\n",
    "   ])\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lambda1 = lambda epoch: epoch // 30\n",
    "lambda2 = lambda epoch: 0.95 ** epoch\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size = 2, gamma = 0.1)\n",
    "\n",
    "model_ft1, train_acc, val_acc, train_loss, val_loss = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=args['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 302 ms\n"
     ]
    }
   ],
   "source": [
    "refined_output_list = []\n",
    "\n",
    "for _list in outputs_list:\n",
    "    refined_output_list.extend(_list[:,0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 151 ms\n"
     ]
    }
   ],
   "source": [
    "refined_output_list = np.array(refined_output_list)\n",
    "refined_output_list = np.where(refined_output_list > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 684 ms\n"
     ]
    }
   ],
   "source": [
    "refined_fakeness_list = []\n",
    "\n",
    "for _list in fakeness_list:\n",
    "    refined_fakeness_list.extend(_list[:,0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.69      0.78     52589\n",
      "           1       0.29      0.57      0.38     11366\n",
      "\n",
      "    accuracy                           0.67     63955\n",
      "   macro avg       0.58      0.63      0.58     63955\n",
      "weighted avg       0.78      0.67      0.71     63955\n",
      "\n",
      "time: 612 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report(refined_output_list, refined_fakeness_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
