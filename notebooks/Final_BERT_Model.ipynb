{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mdeeplearn.soic.iupui.edu\u001b[m  Mon Jul 13 18:17:23 2020\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce GTX 1080   \u001b[m |\u001b[31m 35'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m 8119\u001b[m MB |\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce GTX 1080   \u001b[m |\u001b[31m 35'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m 8119\u001b[m MB |\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 45'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m11019\u001b[m MB |\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 32'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m11019\u001b[m MB |\r\n",
      "\u001b[36m[4]\u001b[m \u001b[34mGeForce GTX 1080   \u001b[m |\u001b[31m 30'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m 8119\u001b[m MB |\r\n",
      "\u001b[36m[5]\u001b[m \u001b[34mGeForce GTX 1080   \u001b[m |\u001b[31m 30'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m 8119\u001b[m MB |\r\n",
      "\u001b[36m[6]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 33'C\u001b[m, \u001b[32m  1 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m11019\u001b[m MB |\r\n",
      "\u001b[36m[7]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 31'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m11019\u001b[m MB |\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "# Create and configure logging module\n",
    "log_format = '%(levelname)s %(asctime)s - %(message)s'\n",
    "logging.basicConfig(filename = '../logs/bert_siamese_v4.logs', \n",
    "                   level = logging.INFO,\n",
    "                   format = log_format,\n",
    "                   filemode = 'w')\n",
    "logger = logging.getLogger()\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 310 ms\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 572 ms\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from random import randrange\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from argparse import ArgumentParser\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce RTX 2080 Ti\n",
      "time: 5.54 s\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 308 ms\n"
     ]
    }
   ],
   "source": [
    "## Arguments\n",
    "\n",
    "args = {\n",
    "    'num_labels' : 2\n",
    "    'const' : 4*768\n",
    "    'batch_size' : 16\n",
    "    'epochs' : 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 300 ms\n"
     ]
    }
   ],
   "source": [
    "train_path = '../data/raw/liar_dataset/train.tsv'\n",
    "test_path = '../data/raw/liar_dataset/test.tsv'\n",
    "val_path = '../data/raw/liar_dataset/valid.tsv'\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(train_path, sep=\"\\t\", header=None)\n",
    "test_df = pd.read_csv(test_path, sep=\"\\t\", header=None)\n",
    "val_df = pd.read_csv(val_path, sep=\"\\t\", header=None)\n",
    "\n",
    "# Fill nan (empty boxes) with 0\n",
    "train_df = train_df.fillna(0)\n",
    "test_df = test_df.fillna(0)\n",
    "val_df = val_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10240/10240 [00:00<00:00, 292391.45it/s]\n",
      "100%|██████████| 1267/1267 [00:00<00:00, 262454.72it/s]\n",
      "100%|██████████| 1284/1284 [00:00<00:00, 291107.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 105 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, trange\n",
    "tqdm.pandas()\n",
    "train_df[14] = train_df[1].progress_apply(lambda x: 1 if (x == 'true' or x == 'mostly-true') else 0)\n",
    "test_df[14] = test_df[1].progress_apply(lambda x: 1 if (x == 'true' or x == 'mostly-true') else 0)\n",
    "val_df[14] = val_df[1].progress_apply(lambda x: 1 if (x == 'true' or x == 'mostly-true') else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 168 ms\n"
     ]
    }
   ],
   "source": [
    "true_train_df = train_df[train_df[14] == 1]\n",
    "false_train_df = train_df[train_df[14] == 0]\n",
    "\n",
    "true_test_df = test_df[test_df[14] == 1]\n",
    "false_test_df = test_df[test_df[14] == 0]\n",
    "\n",
    "true_val_df = val_df[val_df[14] == 1]\n",
    "false_val_df = val_df[val_df[14] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 633 ms\n"
     ]
    }
   ],
   "source": [
    "def true_text(dataframe):\n",
    "    interm_dataframe = dataframe.groupby([4])[2].apply(lambda x: '%s' % ' '.join(x))\n",
    "    interm_dataframe = pd.DataFrame(interm_dataframe)\n",
    "    interm_dataframe.reset_index(inplace = True)\n",
    "    interm_dataframe = interm_dataframe.rename(columns = {4: 4, 2: 15})\n",
    "    return (interm_dataframe)\n",
    "\n",
    "interm_true_train_data = true_text(true_train_df)\n",
    "interm_true_test_data = true_text(true_test_df)\n",
    "interm_true_val_data = true_text(true_val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 674 ms\n"
     ]
    }
   ],
   "source": [
    "def false_text(dataframe):\n",
    "    interm_dataframe = dataframe.groupby([4])[2].apply(lambda x: '%s' % ' '.join(x))\n",
    "    interm_dataframe = pd.DataFrame(interm_dataframe)\n",
    "    interm_dataframe.reset_index(inplace = True)\n",
    "    interm_dataframe = interm_dataframe.rename(columns = {4: 4, 2: 16})\n",
    "    return (interm_dataframe)\n",
    "\n",
    "interm_false_train_data = false_text(false_train_df)\n",
    "interm_false_test_data = false_text(false_test_df)\n",
    "interm_false_val_data = false_text(false_val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 70.9 ms\n"
     ]
    }
   ],
   "source": [
    "train_data = train_df.merge(interm_true_train_data, on = 4, how='left')\n",
    "train_data = train_data.merge(interm_false_train_data, on = 4, how = 'left')\n",
    "\n",
    "test_data = test_df.merge(interm_true_test_data, on = 4, how='left')\n",
    "test_data = test_data.merge(interm_false_test_data, on = 4, how = 'left')\n",
    "\n",
    "val_data = val_df.merge(interm_true_val_data, on = 4, how='left')\n",
    "val_data = val_data.merge(interm_false_val_data, on = 4, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 372 ms\n"
     ]
    }
   ],
   "source": [
    "train_data.fillna(value = 0, inplace = True)\n",
    "test_data.fillna(value = 0, inplace = True)\n",
    "val_data.fillna(value = 0, inplace = True)\n",
    "\n",
    "train_data[15] = train_data[15].astype(str)\n",
    "train_data[16] = train_data[16].astype(str)\n",
    "\n",
    "test_data[15] = test_data[15].astype(str)\n",
    "test_data[16] = test_data[16].astype(str)\n",
    "\n",
    "val_data[15] = val_data[15].astype(str)\n",
    "val_data[16] = val_data[16].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10240 [00:00<?, ?it/s]/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "100%|██████████| 10240/10240 [20:18<00:00,  8.40it/s]\n",
      "  0%|          | 0/1267 [00:00<?, ?it/s]/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "100%|██████████| 1267/1267 [02:30<00:00,  8.44it/s]\n",
      "  0%|          | 0/1284 [00:00<?, ?it/s]/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "100%|██████████| 1284/1284 [02:31<00:00,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 25min 20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in trange(0, train_data.shape[0]):\n",
    "    train_data[15][i] = str(train_data[15][i]).replace(str(train_data[2][i]), '')\n",
    "    train_data[16][i] = str(train_data[16][i]).replace(str(train_data[2][i]), '')\n",
    "    \n",
    "for i in trange(0, test_data.shape[0]):\n",
    "    test_data[15][i] = str(test_data[15][i]).replace(str(test_data[2][i]), '')\n",
    "    test_data[16][i] = str(test_data[16][i]).replace(str(test_data[2][i]), '')\n",
    "    \n",
    "for i in trange(0, val_data.shape[0]):\n",
    "    val_data[15][i] = str(val_data[15][i]).replace(str(val_data[2][i]), '')\n",
    "    val_data[16][i] = str(val_data[16][i]).replace(str(val_data[2][i]), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 28.9 ms\n"
     ]
    }
   ],
   "source": [
    "train = train_data.values\n",
    "test = test_data.values\n",
    "val = val_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "      <td>1</td>\n",
       "      <td>McCain opposed a requirement that the governm...</td>\n",
       "      <td>I'm the only person on this stage who has work...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0            1                                                  2   \\\n",
       "0   2635.json        false  Says the Annies List political group supports ...   \n",
       "1  10540.json    half-true  When did the decline of coal start? It started...   \n",
       "2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "\n",
       "                                   3               4                     5   \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "2                      foreign-policy    barack-obama             President   \n",
       "\n",
       "         6           7     8     9      10     11   12               13  14  \\\n",
       "0     Texas  republican   0.0   1.0    0.0    0.0  0.0         a mailer   0   \n",
       "1  Virginia    democrat   0.0   0.0    1.0    1.0  0.0  a floor speech.   0   \n",
       "2  Illinois    democrat  70.0  71.0  160.0  163.0  9.0           Denver   1   \n",
       "\n",
       "                                                  15  \\\n",
       "0                                                  0   \n",
       "1                                                  0   \n",
       "2   McCain opposed a requirement that the governm...   \n",
       "\n",
       "                                                  16  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2  I'm the only person on this stage who has work...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.14 s\n"
     ]
    }
   ],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.36 s\n"
     ]
    }
   ],
   "source": [
    "labels =        {'train':[train[i][1] for i in range(len(train))], 'test':[test[i][1] for i in range(len(test))], 'val':[val[i][1] for i in range(len(val))]}\n",
    "statements =    {'train':[train[i][2] for i in range(len(train))], 'test':[test[i][2] for i in range(len(test))], 'val':[val[i][2] for i in range(len(val))]}\n",
    "subjects =      {'train':[train[i][3] for i in range(len(train))], 'test':[test[i][3] for i in range(len(test))], 'val':[val[i][3] for i in range(len(val))]}\n",
    "speakers =      {'train':[train[i][4] for i in range(len(train))], 'test':[test[i][4] for i in range(len(test))], 'val':[val[i][4] for i in range(len(val))]}\n",
    "jobs =          {'train':[train[i][5] for i in range(len(train))], 'test':[test[i][5] for i in range(len(test))], 'val':[val[i][5] for i in range(len(val))]}\n",
    "states =        {'train':[train[i][6] for i in range(len(train))], 'test':[test[i][6] for i in range(len(test))], 'val':[val[i][6] for i in range(len(val))]}\n",
    "affiliations =  {'train':[train[i][7] for i in range(len(train))], 'test':[test[i][7] for i in range(len(test))], 'val':[val[i][7] for i in range(len(val))]}\n",
    "credits =       {'train':[train[i][8:13] for i in range(len(train))], 'test':[test[i][8:13] for i in range(len(test))], 'val':[val[i][8:13] for i in range(len(val))]}\n",
    "contexts =      {'train':[train[i][13] for i in range(len(train))], 'test':[test[i][13] for i in range(len(test))], 'val':[val[i][13] for i in range(len(val))]}\n",
    "true_words =    {'train':[train[i][15] for i in range(len(train))], 'test':[test[i][15] for i in range(len(test))], 'val':[val[i][15] for i in range(len(val))]}\n",
    "false_words =   {'train':[train[i][16] for i in range(len(train))], 'test':[test[i][16] for i in range(len(test))], 'val':[val[i][16] for i in range(len(val))]}\n",
    "\n",
    "if num_labels == 6:\n",
    "\n",
    "    def to_onehot(a):\n",
    "        a_cat = [0]*len(a)\n",
    "        for i in range(len(a)):\n",
    "            if a[i]=='true':\n",
    "                a_cat[i] = [1,0,0,0,0,0]\n",
    "            elif a[i]=='mostly-true':\n",
    "                a_cat[i] = [0,1,0,0,0,0]\n",
    "            elif a[i]=='half-true':\n",
    "                a_cat[i] = [0,0,1,0,0,0]\n",
    "            elif a[i]=='barely-true':\n",
    "                a_cat[i] = [0,0,0,1,0,0]\n",
    "            elif a[i]=='false':\n",
    "                a_cat[i] = [0,0,0,0,1,0]\n",
    "            elif a[i]=='pants-fire':\n",
    "                a_cat[i] = [0,0,0,0,0,1]\n",
    "            else:\n",
    "                print('Incorrect label')\n",
    "        return a_cat\n",
    "\n",
    "elif num_labels == 2:\n",
    "\n",
    "    def to_onehot(a):\n",
    "        a_cat = [0]*len(a)\n",
    "        for i in range(len(a)):\n",
    "            if a[i]=='true':\n",
    "                a_cat[i] = [1,0]\n",
    "            elif a[i]=='mostly-true':\n",
    "                a_cat[i] = [1,0]\n",
    "            elif a[i]=='half-true':\n",
    "                a_cat[i] = [0,1]\n",
    "            elif a[i]=='barely-true':\n",
    "                a_cat[i] = [0,1]\n",
    "            elif a[i]=='false':\n",
    "                a_cat[i] = [0,1]\n",
    "            elif a[i]=='pants-fire':\n",
    "                a_cat[i] = [0,1]\n",
    "            else:\n",
    "                print('Incorrect label')\n",
    "        return a_cat\n",
    "\n",
    "else:\n",
    "\n",
    "    print('Invalid number of labels. The number of labels should be either 2 or 6')\n",
    "\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "labels_onehot = {'train':to_onehot(labels['train']), 'test':to_onehot(labels['test']), 'val':to_onehot(labels['val'])}\n",
    "\n",
    "\n",
    "# Preparing metadata\n",
    "metadata = {'train':[0]*len(train), 'val':[0]*len(val), 'test':[0]*len(test)}\n",
    "\n",
    "for i in range(len(train)):\n",
    "    subject = subjects['train'][i]\n",
    "    if subject == 0:\n",
    "        subject = 'None'\n",
    "\n",
    "    speaker = speakers['train'][i]\n",
    "    if speaker == 0:\n",
    "        speaker = 'None'\n",
    "\n",
    "    job = jobs['train'][i]\n",
    "    if job == 0:\n",
    "        job = 'None'\n",
    "\n",
    "    state = states['train'][i]\n",
    "    if state == 0:\n",
    "        state = 'None'\n",
    "\n",
    "    affiliation = affiliations['train'][i]\n",
    "    if affiliation == 0:\n",
    "        affiliation = 'None'\n",
    "\n",
    "    context = contexts['train'][i]\n",
    "    if context == 0 :\n",
    "        context = 'None'\n",
    "\n",
    "    meta = subject + ' ' + speaker + ' ' + job + ' ' + state + ' ' + affiliation + ' ' + context\n",
    "\n",
    "    metadata['train'][i] = meta\n",
    "\n",
    "for i in range(len(val)):\n",
    "    subject = subjects['val'][i]\n",
    "    if subject == 0:\n",
    "        subject = 'None'\n",
    "\n",
    "    speaker = speakers['val'][i]\n",
    "    if speaker == 0:\n",
    "        speaker = 'None'\n",
    "\n",
    "    job = jobs['val'][i]\n",
    "    if job == 0:\n",
    "        job = 'None'\n",
    "\n",
    "    state = states['val'][i]\n",
    "    if state == 0:\n",
    "        state = 'None'\n",
    "\n",
    "    affiliation = affiliations['val'][i]\n",
    "    if affiliation == 0:\n",
    "        affiliation = 'None'\n",
    "\n",
    "    context = contexts['val'][i]\n",
    "    if context == 0 :\n",
    "        context = 'None'\n",
    "\n",
    "    meta = subject + ' ' + speaker + ' ' + job + ' ' + state + ' ' + affiliation + ' ' + context\n",
    "\n",
    "    metadata['val'][i] = meta\n",
    "\n",
    "for i in range(len(test)):\n",
    "    subject = subjects['test'][i]\n",
    "    if subject == 0:\n",
    "        subject = 'None'\n",
    "\n",
    "    speaker = speakers['test'][i]\n",
    "    if speaker == 0:\n",
    "        speaker = 'None'\n",
    "\n",
    "    job = jobs['test'][i]\n",
    "    if job == 0:\n",
    "        job = 'None'\n",
    "\n",
    "    state = states['test'][i]\n",
    "    if state == 0:\n",
    "        state = 'None'\n",
    "\n",
    "    affiliation = affiliations['test'][i]\n",
    "    if affiliation == 0:\n",
    "        affiliation = 'None'\n",
    "\n",
    "    context = contexts['test'][i]\n",
    "    if context == 0 :\n",
    "        context = 'None'\n",
    "\n",
    "    meta = subject + ' ' + speaker + ' ' + job + ' ' + state + ' ' + affiliation + ' ' + context\n",
    "\n",
    "    metadata['test'][i] = meta\n",
    "\n",
    "\n",
    "# Credit score calculation\n",
    "credit_score = {'train':[0]*len(train), 'val':[0]*len(val), 'test':[0]*len(test)}\n",
    "for i in range(len(train)):\n",
    "    credit = credits['train'][i]\n",
    "    if sum(credit) == 0:\n",
    "        score = 0.5\n",
    "    else:\n",
    "        score = (credit[3]*0.2 + credit[2]*0.5 + credit[0]*0.75 + credit[1]*0.9 + credit[4]*1)/(sum(credit))\n",
    "    credit_score['train'][i] = [score for i in range(args['const'])]\n",
    "\n",
    "for i in range(len(val)):\n",
    "    credit = credits['val'][i]\n",
    "    if sum(credit) == 0:\n",
    "        score = 0.5\n",
    "    else:\n",
    "        score = (credit[3]*0.2 + credit[2]*0.5 + credit[0]*0.75 + credit[1]*0.9 + credit[4]*1)/(sum(credit))\n",
    "    credit_score['val'][i] = [score for i in range(args['const'])]\n",
    "\n",
    "for i in range(len(test)):\n",
    "    credit = credits['test'][i]\n",
    "    if sum(credit) == 0:\n",
    "        score = 0.5\n",
    "    else:\n",
    "        score = (credit[3]*0.2 + credit[2]*0.5 + credit[0]*0.75 + credit[1]*0.9 + credit[4]*1)/(sum(credit))\n",
    "    credit_score['test'][i] = [score for i in range(args['const'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=3072, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 s\n"
     ]
    }
   ],
   "source": [
    "class BertLayerNorm(nn.Module):\n",
    "        def __init__(self, hidden_size, eps=1e-12):\n",
    "            \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
    "            \"\"\"\n",
    "            super(BertLayerNorm, self).__init__()\n",
    "            self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "            self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
    "            self.variance_epsilo_n = eps\n",
    "\n",
    "        def forward(self, x):\n",
    "            u = x.mean(-1, keepdim=True)\n",
    "            s = (x - u).pow(2).mean(-1, keepdim=True)\n",
    "            x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
    "            return self.weight * x + self.bias\n",
    "\n",
    "\n",
    "class BertForSequenceClassification(nn.Module):\n",
    "    def __init__(self, num_labels=args['num_labels']): # Change number of labels here.\n",
    "        super(BertForSequenceClassification, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size*4, num_labels)\n",
    "        #self.fc1 = nn.Linear(config.hidden_size*2, 512)\n",
    "        nn.init.xavier_normal_(self.classifier.weight)\n",
    "\n",
    "    def forward_once(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        #logits = self.classifier(pooled_output)\n",
    "\n",
    "        return pooled_output\n",
    "\n",
    "    def forward(self, input_ids1, input_ids2, input_ids3, input_ids4, credit_sc):\n",
    "        \n",
    "        input_ids1 = input_ids1.to(torch.device('cuda'))\n",
    "        input_ids2 = input_ids2.to(torch.device('cuda'))\n",
    "        input_ids3 = input_ids3.to(torch.device('cuda'))\n",
    "        input_ids4 = input_ids4.to(torch.device('cuda'))\n",
    "        credit_sc = credit_sc.to(torch.device('cuda'))\n",
    "        # forward pass of input 1\n",
    "        output1 = self.forward_once(input_ids1, token_type_ids=None, attention_mask=None, labels=None)\n",
    "        # forward pass of input 2\n",
    "        output2 = self.forward_once(input_ids2, token_type_ids=None, attention_mask=None, labels=None)\n",
    "        \n",
    "        output3 = self.forward_once(input_ids3, token_type_ids=None, attention_mask=None, labels=None)\n",
    "        \n",
    "        output4 = self.forward_once(input_ids4, token_type_ids=None, attention_mask=None, labels=None)\n",
    "        out = torch.cat((output1, output2, output3, output4), 1)\n",
    "\n",
    "        out = torch.add(credit_sc, out)\n",
    "\n",
    "        #out = self.fc1(out)\n",
    "        logits = self.classifier(out)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def freeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "from pytorch_pretrained_bert import BertConfig\n",
    "\n",
    "config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
    "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=args['const'])\n",
    "\n",
    "\n",
    "model = BertForSequenceClassification(args['num_labels'])\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mdeeplearn.soic.iupui.edu\u001b[m  Mon Jul 13 18:43:18 2020\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce GTX 1080   \u001b[m |\u001b[31m 28'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    2\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce GTX 1080   \u001b[m |\u001b[31m 28'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    2\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[2]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 30'C\u001b[m, \u001b[32m  3 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 1410\u001b[m / \u001b[33m11019\u001b[m MB | \u001b[1m\u001b[30manbhimi\u001b[m(\u001b[33m1407M\u001b[m)\n",
      "\u001b[36m[3]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 26'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    3\u001b[m / \u001b[33m11019\u001b[m MB |\n",
      "\u001b[36m[4]\u001b[m \u001b[34mGeForce GTX 1080   \u001b[m |\u001b[31m 28'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    2\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[5]\u001b[m \u001b[34mGeForce GTX 1080   \u001b[m |\u001b[31m 28'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    2\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[6]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 30'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    3\u001b[m / \u001b[33m11019\u001b[m MB |\n",
      "\u001b[36m[7]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 29'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    3\u001b[m / \u001b[33m11019\u001b[m MB |\n",
      "time: 475 ms\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.33 s\n"
     ]
    }
   ],
   "source": [
    "# Loading the statements\n",
    "X_train = statements['train']\n",
    "y_train = labels_onehot['train']\n",
    "\n",
    "X_val = statements['val']\n",
    "y_val = labels_onehot['val']\n",
    "\n",
    "X_train = X_train + X_val\n",
    "y_train = y_train + y_val\n",
    "\n",
    "\n",
    "X_test = statements['test']\n",
    "y_test = labels_onehot['test']\n",
    "\n",
    "# Loading the meta data\n",
    "X_train_meta = metadata['train']\n",
    "X_val_meta = metadata['val']\n",
    "X_train_meta = X_train_meta + X_val_meta\n",
    "X_test_meta = metadata['test']\n",
    "\n",
    "# Loading Credit scores\n",
    "\n",
    "X_train_credit = credit_score['train']\n",
    "X_val_credit = credit_score['val']\n",
    "X_train_credit = X_train_credit+X_val_credit\n",
    "X_test_credit = credit_score['test']\n",
    "\n",
    "X_train_true_words = true_words['train']+true_words['val']\n",
    "X_test_true_words = true_words['test']\n",
    "\n",
    "X_train_false_words = false_words['train']+false_words['val']\n",
    "X_test_false_words = false_words['test']\n",
    "\n",
    "max_seq_length_stat = 64\n",
    "max_seq_length_words = 64\n",
    "max_seq_length_meta = 32\n",
    "\n",
    "class text_dataset(Dataset):\n",
    "    def __init__(self,x_y_list, transform=None):\n",
    "\n",
    "        self.x_y_list = x_y_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "\n",
    "        # Tokenize statements\n",
    "        tokenized_review = tokenizer.tokenize(self.x_y_list[0][index])\n",
    "\n",
    "        if len(tokenized_review) > max_seq_length_stat:\n",
    "            tokenized_review = tokenized_review[:max_seq_length_stat]\n",
    "\n",
    "        ids_review  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
    "\n",
    "        padding = [0] * (max_seq_length_stat - len(ids_review))\n",
    "\n",
    "        ids_review += padding\n",
    "\n",
    "        assert len(ids_review) == max_seq_length_stat\n",
    "\n",
    "        #print(ids_review)\n",
    "        ids_review = torch.tensor(ids_review)\n",
    "\n",
    "        # Tokenize metadata\n",
    "\n",
    "        tokenized_review_meta = tokenizer.tokenize(self.x_y_list[1][index])\n",
    "\n",
    "        if len(tokenized_review_meta) > max_seq_length_meta:\n",
    "            tokenized_review_meta = tokenized_review_meta[:max_seq_length_meta]\n",
    "\n",
    "        ids_review_meta = tokenizer.convert_tokens_to_ids(tokenized_review_meta)\n",
    "\n",
    "        padding = [0] * (max_seq_length_meta - len(ids_review_meta))\n",
    "\n",
    "        ids_review_meta += padding\n",
    "\n",
    "        assert len(ids_review_meta) == max_seq_length_meta\n",
    "\n",
    "        #print(ids_review)\n",
    "        ids_review_meta = torch.tensor(ids_review_meta)\n",
    "\n",
    "        fakeness = self.x_y_list[5][index] # color\n",
    "        list_of_labels = [torch.from_numpy(np.array(fakeness))]\n",
    "        \n",
    "        # Tokenize True Words\n",
    "        tokenized_true_words = tokenizer.tokenize(self.x_y_list[2][index])\n",
    "        \n",
    "        if len(tokenized_true_words) > max_seq_length_words:\n",
    "            tokenized_true_words = tokenized_true_words[:max_seq_length_words]\n",
    "            \n",
    "        ids_true_words = tokenizer.convert_tokens_to_ids(tokenized_true_words)\n",
    "        padding = [0]*(max_seq_length_words - len(ids_true_words))\n",
    "        ids_true_words += padding\n",
    "        assert len(ids_true_words) == max_seq_length_words\n",
    "        ids_true_words = torch.tensor(ids_true_words)\n",
    "        \n",
    "        # Tokenize False Words\n",
    "        tokenized_false_words = tokenizer.tokenize(self.x_y_list[3][index])\n",
    "        \n",
    "        if len(tokenized_false_words) > max_seq_length_words:\n",
    "            tokenized_false_words = tokenized_false_words[:max_seq_length_words]\n",
    "            \n",
    "        ids_false_words = tokenizer.convert_tokens_to_ids(tokenized_false_words)\n",
    "        padding = [0]*(max_seq_length_words - len(ids_false_words))\n",
    "        ids_false_words += padding\n",
    "        assert len(ids_false_words) == max_seq_length_words\n",
    "        ids_false_words = torch.tensor(ids_false_words)\n",
    "        \n",
    "        credit_scr = self.x_y_list[4][index] # Credit score\n",
    "        credit_scr = torch.tensor(credit_scr)\n",
    "        \n",
    "        return [ids_review, ids_review_meta, ids_true_words, ids_false_words, credit_scr], list_of_labels[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_y_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 343 ms\n"
     ]
    }
   ],
   "source": [
    "# Train Statements and Justifications\n",
    "train_lists = [X_train, X_train_meta, X_train_true_words, X_train_false_words, X_train_credit, y_train]\n",
    "\n",
    "# Test Statements and Justifications\n",
    "test_lists = [X_test, X_train_meta, X_test_true_words, X_test_false_words, X_test_credit, y_test]\n",
    "\n",
    "# Preparing the data (Tokenize)\n",
    "training_dataset = text_dataset(x_y_list = train_lists)\n",
    "test_dataset = text_dataset(x_y_list = test_lists)\n",
    "\n",
    "# Prepare the training dictionaries\n",
    "dataloaders_dict = {'train': torch.utils.data.DataLoader(training_dataset, batch_size=args['batch_size'], shuffle=True, num_workers=0),\n",
    "                   'val':torch.utils.data.DataLoader(test_dataset, batch_size=args['batch_size'], shuffle=False, num_workers=0)\n",
    "                   }\n",
    "dataset_sizes = {'train':len(train_lists[0]),\n",
    "                'val':len(test_lists[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anbhimi/.local/lib/python3.5/site-packages/torch/optim/lr_scheduler.py:82: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train total loss: 0.5268 \n",
      "train fakeness_acc: 0.7680\n",
      "val total loss: 0.4478 \n",
      "val fakeness_acc: 0.8508\n",
      "Saving with accuracy of 0.850828729281768 improved over previous 0\n",
      "Time taken for epoch1 is 10.513406018416086 minutes\n",
      "\n",
      "Epoch 2/5\n",
      "----------\n",
      "train total loss: 0.4916 \n",
      "train fakeness_acc: 0.8056\n",
      "val total loss: 0.4446 \n",
      "val fakeness_acc: 0.8564\n",
      "Saving with accuracy of 0.856353591160221 improved over previous 0.850828729281768\n",
      "Time taken for epoch2 is 10.529628002643586 minutes\n",
      "\n",
      "Epoch 3/5\n",
      "----------\n",
      "train total loss: 0.4847 \n",
      "train fakeness_acc: 0.8187\n",
      "val total loss: 0.4448 \n",
      "val fakeness_acc: 0.8571\n",
      "Saving with accuracy of 0.8571428571428571 improved over previous 0.856353591160221\n",
      "Time taken for epoch3 is 10.54173267285029 minutes\n",
      "\n",
      "Epoch 4/5\n",
      "----------\n",
      "train total loss: 0.4773 \n",
      "train fakeness_acc: 0.8270\n",
      "val total loss: 0.4450 \n",
      "val fakeness_acc: 0.8571\n",
      "Time taken for epoch4 is 10.44638971487681 minutes\n",
      "\n",
      "Epoch 5/5\n",
      "----------\n",
      "train total loss: 0.4781 \n",
      "train fakeness_acc: 0.8264\n",
      "val total loss: 0.4452 \n",
      "val fakeness_acc: 0.8571\n",
      "Time taken for epoch5 is 10.460951109727224 minutes\n",
      "\n",
      "Training complete in 52m 30s\n",
      "Best val Acc: 0.857143\n",
      "time: 52min 30s\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)\n",
    "\n",
    "logger.info('Training begins')\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "outputs_list = []\n",
    "fakeness_list = []\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=4):\n",
    "    since = time.time()\n",
    "    print('starting')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 100\n",
    "    best_acc = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        logger.info('Training the epoch : {}'.format(epoch+1))\n",
    "        logger.debug('Training stopped at epoch : {}'.format(epoch))\n",
    "        epoch_start = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            fakeness_corrects = 0\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for inputs, fakeness in dataloaders_dict[phase]:\n",
    "                \n",
    "                inputs1 = inputs[0] # News statement input\n",
    "                inputs2 = inputs[1] # Meta data input\n",
    "                inputs3 = inputs[2] # True Words\n",
    "                inputs4 = inputs[3] # False Words\n",
    "                inputs5 = inputs[4] # Credit scores input\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    #print(inputs)\n",
    "                    outputs = model(inputs1, inputs2, inputs3, inputs4, inputs5)\n",
    "\n",
    "                    outputs = F.softmax(outputs,dim=1)\n",
    "                    outputs_list.append(outputs)\n",
    "                    \n",
    "                    fakeness = fakeness.to(torch.device('cuda'))\n",
    "                    fakeness_list.append(fakeness)\n",
    "                    loss = criterion(outputs, torch.max(fakeness.float(), 1)[1])\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs1.size(0)\n",
    "\n",
    "                fakeness_corrects += torch.sum(torch.max(outputs, 1)[1] == torch.max(fakeness, 1)[1])\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "\n",
    "            fakeness_acc = fakeness_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} total loss: {:.4f} '.format(phase,epoch_loss ))\n",
    "            print('{} fakeness_acc: {:.4f}'.format(\n",
    "                phase, fakeness_acc))\n",
    "\n",
    "            # Saving training acc and loss for each epoch\n",
    "            fakeness_acc1 = fakeness_acc.data\n",
    "            fakeness_acc1 = fakeness_acc1.cpu()\n",
    "            fakeness_acc1 = fakeness_acc1.numpy()\n",
    "            train_acc.append(fakeness_acc1)\n",
    "            train_loss.append(epoch_loss)\n",
    "\n",
    "            if phase == 'val' and fakeness_acc > best_acc:\n",
    "                print('Saving with accuracy of {}'.format(fakeness_acc),\n",
    "                      'improved over previous {}'.format(best_acc))\n",
    "                best_acc = fakeness_acc\n",
    "\n",
    "                # Saving val acc and loss for each epoch\n",
    "                fakeness_acc1 = fakeness_acc.data\n",
    "                fakeness_acc1 = fakeness_acc1.cpu()\n",
    "                fakeness_acc1 = fakeness_acc1.numpy()\n",
    "                val_acc.append(fakeness_acc1)\n",
    "                val_loss.append(epoch_loss)\n",
    "\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model.state_dict(), 'bert_model_test_noFC1_triBERT_binary_focalloss.pth')\n",
    "\n",
    "        print('Time taken for epoch'+ str(epoch+1)+ ' is ' + str((time.time() - epoch_start)/60) + ' minutes')\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(float(best_acc)))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, train_acc, val_acc, train_loss, val_loss\n",
    "\n",
    "lrlast = .0001\n",
    "lrmain = .00001\n",
    "optim1 = optim.Adam(\n",
    "    [\n",
    "        {\"params\":model.bert.parameters(),\"lr\": lrmain},\n",
    "        {\"params\":model.classifier.parameters(), \"lr\": lrlast},\n",
    "\n",
    "   ])\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "'''import focal_loss\n",
    "loss_args = {\"alpha\": 0.5, \"gamma\": 2.0}\n",
    "criterion = focal_loss.FocalLoss(*loss_args)'''\n",
    "\n",
    "lambda1 = lambda epoch: epoch // 30\n",
    "lambda2 = lambda epoch: 0.95 ** epoch\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size = 2, gamma = 0.1)\n",
    "\n",
    "model_ft1, train_acc, val_acc, train_loss, val_loss = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=args['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 336 ms\n"
     ]
    }
   ],
   "source": [
    "refined_output_list = []\n",
    "\n",
    "for _list in outputs_list:\n",
    "    refined_output_list.extend(_list[:,0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 669 ms\n"
     ]
    }
   ],
   "source": [
    "refined_output_list = np.array(refined_output_list)\n",
    "refined_output_list = np.where(refined_output_list > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 497 ms\n"
     ]
    }
   ],
   "source": [
    "refined_fakeness_list = []\n",
    "\n",
    "for _list in fakeness_list:\n",
    "    refined_fakeness_list.extend(_list[:,0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.87     47290\n",
      "           1       0.61      0.82      0.70     16665\n",
      "\n",
      "    accuracy                           0.81     63955\n",
      "   macro avg       0.77      0.82      0.78     63955\n",
      "weighted avg       0.84      0.81      0.82     63955\n",
      "\n",
      "time: 599 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report(refined_output_list, refined_fakeness_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
