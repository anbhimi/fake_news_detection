INFO 2020-07-13 17:34:03,977 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/anbhimi/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2020-07-13 17:34:19,804 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/anbhimi/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2020-07-13 17:34:19,806 - extracting archive file /home/anbhimi/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpqjk1ty3o
INFO 2020-07-13 17:34:26,501 - Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2020-07-13 17:34:37,606 - Training begins
INFO 2020-07-13 17:34:37,640 - Training the epoch : 1
INFO 2020-07-13 17:37:04,725 - Training the epoch : 2
INFO 2020-07-13 17:39:32,488 - Training the epoch : 3
INFO 2020-07-13 17:41:58,818 - Training the epoch : 4
INFO 2020-07-13 17:44:24,767 - Training the epoch : 5
